\chapter{Experimental Design}
\section*{IdeoEvo Project:}
\label{chap:experimental-design}

\section*{Executive Summary}

The IdeoEvo Project (\textit{\textbf{Ideas Evolution Experimental Validation}}) represents the first randomized controlled study designed to empirically validate the effectiveness of the Pyragogic Model. The study adopts a 2×2×2 factorial design with 264 participants to test whether learning in a pyragogic environment produces superior results compared to traditional collaborative methods. The project spans 15 months, from preparation to dissemination, and integrates quantitative and qualitative methods for a comprehensive evaluation of the proposed pedagogical innovation.

\section{Theoretical Foundation and Methodology}
\subsection*{Need for empirical validation:}

The Pyragogic Model, while grounded in solid multidisciplinary theoretical foundations, requires rigorous empirical validation to establish its effectiveness relative to established educational approaches. The complexity of the system---with its multi-level dynamics, innovative metrics, and procedural artificial intelligence integration---requires a sophisticated experimental design capable of capturing both direct effects and emergent properties of the learning ecosystem.

The Project has been designed as a multi-phase randomized controlled study. The objective is to systematically test the central hypotheses of pyragogic theory under rigorous experimental conditions representative of real educational contexts.

\subsection{Methodological paradigm}

The project adopts a mixed-methods approach anchored to the \textit{design-based research} paradigm \cite{Brown1992}, characterized by:

\begin{itemize}
    \item \textbf{Iterative design}: Cycles of implementation, evaluation, and refinement
    \item \textbf{Collaborative partnership}: Co-design with educators and students  
    \item \textbf{Real-world context}: Testing in authentic educational environments
    \item \textbf{Theory building}: Simultaneous contribution to theory and practice
    \item \textbf{Multiple dependent variables}: Measurement of multiple outcomes and interactions
\end{itemize}

The epistemological framework adopted is that of \textit{scientific pragmatism} \cite{Dewey1938}, which privileges practical utility and empirical effectiveness as criteria for theoretical validation.

\section{Objectives and Hypothesis System}
\subsection*{Primary objectives:}

\textbf{PO1: Comparative effectiveness of the model}

Demonstrate that learning in a pyragogic environment produces superior results in terms of:
\begin{itemize}
    \item Quality of ideas generated (measured via EQI)
    \item Critical and creative thinking skills
    \item Cognitive collaboration capabilities
    \item Intrinsic motivation for learning
    \item Knowledge retention and transfer
\end{itemize}

\textbf{PO2: Validation of the metrics system}

Establish psychometric validity and pedagogical utility of:
\begin{itemize}
    \item Epistemic Quality Index (EQI)
    \item Reciprocity Coefficient (RC) 
    \item Cognitive Diversity Index (CDI)
    \item Systemic Resilience (SR)
\end{itemize}

\textbf{PO3: AI integration optimization}

Determine optimal configuration of procedural AI for:
\begin{itemize}
    \item Facilitation of learning processes
    \item Mitigation of cognitive biases
    \item Support for cognitive reciprocity
    \item Maintenance of decisional autonomy
\end{itemize}

\subsection{Secondary objectives}

\textbf{SO1: Identification of moderators and mediators}
\begin{itemize}
    \item Individual characteristics that predict pyragogic success
    \item Contextual factors that facilitate or impede implementation
    \item Causal mechanisms underlying observed effects
\end{itemize}

\textbf{SO2: Development of implementation guidelines}
\begin{itemize}
    \item Replicable protocols for different disciplines
    \item Strategies for managing resistance
    \item Framework for facilitator training
\end{itemize}

\textbf{SO3: Cost-benefit analysis}
\begin{itemize}
    \item Resources required for implementation
    \item Cost-benefit ratio compared to traditional approaches
    \item Model scalability
\end{itemize}

\newpage

\subsection{Structured hypothesis system}

\textbf{Main Hypothesis (H1)}: 
Students in the pyragogic condition will show significantly superior performance compared to the control group across a battery of educational outcomes, with effect size $d \geq 0{,}5$ for primary measures.

\textbf{---Specific Hypotheses}

\textbf{H1a -- Epistemic quality}: 
\begin{equation}
\text{EQI}_{\text{pyragogy}} > \text{EQI}_{\text{control}} + 0{,}5 \sigma_{\text{pooled}}
\label{eq:h1a}
\end{equation}

\textbf{H1b -- Critical thinking}: Watson-Glaser Critical Thinking Appraisal scores will be significantly higher in the pyragogic group (Cohen's $d$ $\geq 0{,}5$).

\textbf{H1c -- Creativity}: Originality and flexibility scores on the Torrance Test of Creative Thinking will be superior in the experimental group.

\textbf{H1d -- Collaboration}: Average Reciprocity Coefficient will be $\geq 0{,}75$ in the pyragogic group versus $\leq 0{,}45$ in the control.

\textbf{H1e -- Motivation}: Intrinsic Motivation Inventory scores will show significantly superior effects in the experimental group.

\textbf{Secondary Hypotheses}:

\textbf{H2 -- Moderation by cognitive diversity}: The effect of pyragogic treatment will be moderated by the group's Cognitive Diversity Index, with stronger effects in high-diversity groups.

\textbf{H3 -- Mediation through reciprocity}: The treatment effect on learning outcomes will be mediated by the Reciprocity Coefficient.

\textbf{H4 -- Interaction with AI}: The presence of procedural AI will amplify pyragogic effects, with significant treatment × AI interaction.

\section{Methodology and Experimental Design}
\subsection*{General design:}

\textbf{Study type}: Randomized controlled trial (RCT) with 2×2×2 factorial design

\textbf{Experimental factors}:
\begin{itemize}
    \item \textbf{Factor A}: Pedagogical modality (Pyragogy vs. Traditional Collaborative Learning)
    \item \textbf{Factor B}: AI presence (With vs. Without procedural AI support)
    \item \textbf{Factor C}: Exposure duration (8 vs. 16 weeks)
\end{itemize}

\textbf{Resulting experimental conditions}:
\begin{enumerate}
    \item Pyragogy + AI + 8 weeks (PY-AI-8)
    \item Pyragogy + AI + 16 weeks (PY-AI-16)
    \item Pyragogy + No AI + 8 weeks (PY-NoAI-8)
    \item Pyragogy + No AI + 16 weeks (PY-NoAI-16)
    \item Traditional + AI + 8 weeks (TR-AI-8)
    \item Traditional + AI + 16 weeks (TR-AI-16)
    \item Traditional + No AI + 8 weeks (TR-NoAI-8)
    \item Traditional + No AI + 16 weeks (TR-NoAI-16)
\end{enumerate}

\subsection{Statistical analysis and sample size determination}

\textbf{Power analysis parameters}:
\begin{itemize}
    \item Expected effect size: $d = 0{,}6$ (medium-large, based on cooperative learning meta-analyses)
    \item Desired power: $1 - \beta = 0{,}90$
    \item Significance level: $\alpha = 0{,}05$
    \item Test: 2×2×2 factorial ANOVA
\end{itemize}

\textbf{Sample size calculation}: 
Using G*Power 3.1.9.7 \cite{Faul2007}:

\begin{equation}
n_{\text{per group}} = \frac{2(z_{\alpha/2} + z_\beta)^2 \sigma^2}{\delta^2} \times \text{Design Effect}
\label{eq:power-analysis}
\end{equation}

where $\delta = d \times \sigma$ is the minimum detectable difference.

\textbf{Result}: $n = 28$ per group, for a total of $N = 224$ participants.

\textbf{Dropout adjustment}: Considering a 15\% dropout rate typical in longitudinal educational studies \cite{Shadish2002}:

\begin{equation}
N_{\text{corrected}} = \frac{224}{1 - 0{,}15} = 264 \text{ participants}
\label{eq:dropout-adjustment}
\end{equation}

\subsection{Inclusion and exclusion criteria}

\textbf{Inclusion criteria}:
\begin{itemize}
    \item University students (18-25 years)
    \item Enrollment in Education Sciences or Computer Engineering courses
    \item English proficiency at B2 level or higher (for standardized instruments)
    \item Availability for the entire experimental period
    \item Signed informed consent
\end{itemize}

\textbf{Exclusion criteria}:
\begin{itemize}
    \item Significant prior experience with pyragogic methodologies
    \item Simultaneous participation in other educational experimental studies
    \item Anticipated absences exceeding 20\% of the experimental period
\end{itemize}

\textbf{Sample stratification}: 
Stratified randomization by:
\begin{itemize}
    \item Gender (50:50 balance $\pm$ 10\%)
    \item Disciplinary area (Education vs. Computer Science)
    \item Baseline academic performance (GPA tertiles)
    \item Cognitive style (Kolb Learning Style Inventory)
\end{itemize}

\newpage

\section{Detailed Experimental Protocols}
\subsection*{Pre-screening and initial assessment phase:}

\textbf{Week -2: Recruitment and screening}

\begin{algorithm}[H]
\caption{Recruitment Protocol}
\label{alg:recruitment}
\begin{algorithmic}[1]
\State \textbf{Phase 1:} Recruitment through university channels
\State Send informational emails to eligible courses ($N \approx 2,000$ students)
\State Organize 4 information sessions (2 per campus)

\State \textbf{Phase 2:} Initial screening (online questionnaire, 15 min)
\For{each interested candidate}
    \State Verify inclusion/exclusion criteria
    \State Administer brief cognitive test
    \State Collect demographic data
    \State Assess motivation and availability
\EndFor
\State \textbf{Phase 3:} Selection and invitation
\State Rank candidates by suitability and motivation
\State Invite first 320 candidates (considering 20\% no-shows)
\State Send detailed information and consent forms
\end{algorithmic}
\end{algorithm}

\textbf{Week -1: Baseline assessment}

\textbf{Cognitive Assessment (90 min)}:
\begin{itemize}
    \item Watson-Glaser Critical Thinking Appraisal - Form S \cite{Watson2012}
    \item Torrance Tests of Creative Thinking - Verbal Form A \cite{Torrance1966}
    \item Need for Cognition Scale - Short Form \cite{Cacioppo1984}
    \item Kolb Learning Style Inventory - Version 4 \cite{Kolb2013}
\end{itemize}

\textbf{Motivational Assessment (30 min)}:
\begin{itemize}
    \item Intrinsic Motivation Inventory \cite{Ryan1982}
    \item Academic Self-Regulation Questionnaire \cite{Ryan1998}
    \item Mindset Scale (Growth vs. Fixed) \cite{Dweck2006}
\end{itemize}

\textbf{Socio-Cognitive Assessment (45 min)}:
\begin{itemize}
    \item Collaborative Learning Attitudes Survey \cite{Johnson1991}
    \item Perspective-Taking subscale (Interpersonal Reactivity Index) \cite{Davis1980}
    \item Argumentativeness Scale \cite{Infante1982}
\end{itemize}

\textbf{Baseline Performance Task (60 min)}:
Standardized complex problem-solving task to measure:
\begin{itemize}
    \item Quality of initial ideas (scored via EQI)
    \item Basic collaborative abilities
    \item Baseline for cognitive reciprocity
\end{itemize}

\subsection{Randomization and group formation}

\begin{algorithm}[H]
\caption{Stratified Randomization}
\label{alg:randomization}
\begin{algorithmic}[1]
\State \textbf{Input:} Pool of $N=264$ validated participants

\State \textbf{Phase 1:} Stratification
\For{each demographic stratum $s$}
    \State Filter participants by stratum criteria
    \State $n_s \gets$ number of participants in stratum
\EndFor

\State \textbf{Phase 2:} Block randomization within strata
\For{each stratum $s$}
    \State Generate random permutation of assignments
    \State Use blocks of size 8 (one per condition)
    \State Assign participants sequentially
\EndFor

\State \textbf{Phase 3:} Group formation
\For{each condition $c$}
    \State Form groups of $n=12$--14 participants
    \State Balance groups for baseline characteristics
    \State Assign unique identifiers to groups
\EndFor

\State \textbf{Output:} Assignment list with concealed allocation
\end{algorithmic}
\end{algorithm}

\newpage

\textbf{Allocation concealment}:
\begin{itemize}
    \item Randomization performed by independent statistician
    \item Assignment list sealed until moment of assignment
    \item Researchers blinded to condition during baseline assessment
    \item Participants informed of their condition only after completion of initial tests
\end{itemize}

\subsection{Experimental interventions}

\textbf{Pyragogic Condition}:

\textbf{Weeks 1--2: Ecosystem Stabilization}
\begin{itemize}
    \item \textbf{Session 1}: Introduction to pyragogic principles
        \begin{itemize}
            \item Theoretical workshop (60 min): Cognitive intraspecific selection
            \item Practical experience (90 min): First implementation of rituals
            \item Platform orientation (30 min): Introduction to technological tools
        \end{itemize}
    \item \textbf{Sessions 2--4}: Calibration and practice
        \begin{itemize}
            \item Cognitive micro-tournaments on simple problems
            \item Experiments with different roles (supporter, critic, synthesizer)
            \item Immediate feedback on EQI and RC metrics
        \end{itemize}
    \item \textbf{Sessions 5--6}: Gradual Challenge
        \begin{itemize}
            \item Introduction of more complex problems
            \item First experiences of collaborative synthesis
            \item Stabilization of group norms
        \end{itemize}
\end{itemize}

\textbf{Weeks 3--6: Evolutionary Intensification}
\begin{itemize}
    \item \textbf{Main Challenge Introduction}: Complex multidisciplinary problem
    \item \textbf{Complete Cognitive Tournament}: Implementation of complete protocol
    \item \textbf{AI Integration} (AI conditions): Gradual activation of 6 AI modules
    \item \textbf{Meta-Cognitive Reflection}: Weekly sessions of process self-analysis
\end{itemize}

\textbf{Weeks 7--8/16: Consolidation and Transmission}
\begin{itemize}
    \item \textbf{Selection of Fittest Ideas}: Identification of most robust ideas
    \item \textbf{Inter-Group Tournaments}: Constructive competition between groups
    \item \textbf{Knowledge Transmission}: Preparation for teaching other groups
    \item \textbf{Ecosystem Evaluation}: Final assessment of group evolution
\end{itemize}

\textbf{Control Condition (Traditional Collaborative Learning)}:

Implementation of the Johnson \& Johnson model \cite{Johnson1999} with:
\begin{itemize}
    \item \textbf{Positive Interdependence}: Common goals and complementary roles
    \item \textbf{Individual Accountability}: Personal responsibility for contributions
    \item \textbf{Face-to-Face Interaction}: Encouragement and mutual support
    \item \textbf{Social Skills Training}: Development of interpersonal competencies
    \item \textbf{Group Processing}: Periodic reflection on group processes
\end{itemize}

\emph{Same schedule and intensity as pyragogic condition to ensure comparability.}

\subsection{Longitudinal measurement protocols}

\textbf{Continuous measurement (each session)}:
\begin{itemize}
    \item \textbf{Automatic recording}: All verbal and textual exchanges
    \item \textbf{EQI calculation}: Real-time computation of idea quality
    \item \textbf{RC monitoring}: Continuous tracking of reciprocity
    \item \textbf{Participation metrics}: Frequency, duration, and quality of interventions
\end{itemize}

\textbf{Weekly measurement}:
\begin{itemize}
    \item \textbf{Mood and motivation check}: Brief self-report (5 min)
    \item \textbf{Group cohesion}: Team Diagnostic Survey \cite{Wageman1995} (10 min)
    \item \textbf{Learning satisfaction}: Course experience questionnaire (5 min)
\end{itemize}

\newpage

\textbf{Monthly measurement}:
\begin{itemize}
    \item \textbf{Cognitive skills update}: Abbreviated versions of tests
    \item \textbf{Knowledge acquisition}: Domain-specific personalized assessments
    \item \textbf{Transfer tasks}: Novel problems to assess transfer
\end{itemize}

\textbf{Final assessment}:
Complete replication of baseline battery plus additions:
\begin{itemize}
    \item \textbf{Portfolio evaluation}: Expert judgment of longitudinal growth
    \item \textbf{Peer evaluations}: 360-degree assessment of collaboration
    \item \textbf{Retention tests}: Knowledge recall after 2 weeks
    \item \textbf{Transfer challenge}: Application of skills in new domain
    \item \textbf{Satisfaction and experience}: In-depth qualitative questionnaire
\end{itemize}

\section{Measurement and Validation Instruments}
\subsection*{Standardized instruments:}

\textbf{Watson-Glaser Critical Thinking Appraisal -- Form S}
\begin{itemize}
	\item \textbf{Construct}: 5 dimensions of critical thinking
	\item \textbf{Items}: 40 scenarios with multiple-choice responses
	\item \textbf{Time}: 30 minutes
	\item \textbf{Reliability}: $\alpha = 0{,}85$ (Cronbach's alpha)
	\item \textbf{Validity}: Correlations $0{,}6$--$0{,}7$ with academic performance
\end{itemize}

\textbf{Torrance Tests of Creative Thinking -- Verbal}
\begin{itemize}
	\item \textbf{Construct}: Fluency, Flexibility, Originality, Elaboration
	\item \textbf{Subtests}: 6 verbal creative activities
	\item \textbf{Time}: 45 minutes
	\item \textbf{Scoring}: Consensual assessment by 2 independent raters
	\item \textbf{Inter-rater reliability}: $r > 0{,}90$
\end{itemize}

\textbf{Intrinsic Motivation Inventory}
\begin{itemize}
	\item \textbf{Dimensions}: Interest/Enjoyment, Perceived Competence, Effort/Importance, Pressure/Tension
	\item \textbf{Items}: 22 items on 7-point Likert scale
	\item \textbf{Validity}: Validated in over 200 motivation studies
	\item \textbf{Reliability}: $\alpha = 0{,}74$--$0{,}84$ per subscale
\end{itemize}

\subsection{Custom-developed instruments}

\textbf{Complex Problem Solving Assessment (CPSA)}

Developed specifically to capture pyragogic competencies:

\textbf{CPSA Structure}:
\begin{enumerate}
    \item \textbf{Individual Phase (20 min)}:
        \begin{itemize}
            \item Presentation of complex multidisciplinary scenario
            \item Individual generation of ideas and solutions
            \item Self-assessment of own idea quality
        \end{itemize}
    \item \textbf{Collaborative Phase (40 min)}:
        \begin{itemize}
            \item Formation of random triads
            \item Sharing and comparison of individual ideas
            \item Negotiation toward integrated solutions
            \item Documentation of decision-making process
        \end{itemize}
    \item \textbf{Reflection Phase (10 min)}:
        \begin{itemize}
            \item Meta-cognitive reflection on process
            \item Identification of learnings and insights
            \item Evaluation of collaborative experience
        \end{itemize}
\end{enumerate}

\textbf{CPSA Scoring}:
\begin{itemize}
    \item \textbf{Individual Idea Quality}: Automatic EQI + expert evaluation
    \item \textbf{Collaborative Process}: Analysis of reciprocity and construction
    \item \textbf{Final Solution Quality}: EQI + innovation + feasibility
    \item \textbf{Meta-Cognitive Awareness}: Qualitative analysis of reflections
\end{itemize}

\textbf{Collaborative Intelligence Scale (CIS)}

New instrument to measure co-thinking capabilities:

\begin{table}[ht]
\centering
\caption{Dimensions of the Collaborative Intelligence Scale}
\label{tab:cis-dimensions}
\begin{tabular}{p{3cm}p{5cm}p{4.5cm}}
\toprule
\textbf{Dimension} & \textbf{Description} & \textbf{Example Item} \\
\midrule
\textbf{Cognitive Empathy} & Ability to understand others' perspectives & ``I easily understand how others think about problems'' \\
\hline
\textbf{Idea Integration} & Skill in synthesizing diverse perspectives & ``I'm good at combining different viewpoints into new solutions'' \\
\hline  
\textbf{Constructive Conflict} & Productive management of disagreement & ``I can disagree with others while maintaining good relationships'' \\
\hline
\textbf{Reciprocal Teaching} & Simultaneous teaching and learning & ``When I explain something, I often learn new things'' \\
\hline
\textbf{Collective Efficacy} & Confidence in group capability & ``Our group can solve problems that individuals cannot'' \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Qualitative analysis methodologies}

\textbf{Video Session Protocol Analysis}

Systematic coding of interactions using modified schema from Interaction Analysis \cite{Jordan1995}:
\begin{itemize}
    \item \textbf{Idea Generation Events}: Moments of new idea introduction
    \item \textbf{Challenge Events}: Episodes of constructive criticism or devil's advocacy
    \item \textbf{Synthesis Events}: Integration of previous ideas into hybrid solutions
    \item \textbf{Meta-Cognitive Events}: Explicit reflections on thinking processes
    \item \textbf{Social Maintenance Events}: Behaviors to maintain social cohesion
\end{itemize}

\textbf{Discourse Analysis}

Software-assisted linguistic analysis (NVIVO 12) to identify:
\begin{itemize}
    \item Argumentative patterns (claim-evidence-warrant structures)
    \item Linguistic markers of uncertainty, confidence, openness
    \item Evolution of disciplinary vocabulary
    \item Perspective-taking and cognitive empathy markers
\end{itemize}

\textbf{Social Network Analysis}

Dynamic mapping of cognitive interactions:

\begin{equation}
\text{Centrality}(i) = \frac{\sum_{j \neq i} \text{Reciprocity}(i,j)}{N-1}
\label{eq:cognitive-centrality}
\end{equation}

\begin{equation}
\text{Clustering}(G) = \frac{3 \times \text{Number of triangles}}{3 \times \text{Number of connected triples}}
\label{eq:clustering-coefficient}
\end{equation}

\section{Statistical Analysis Plan}
\subsection*{General analytical approach:}

The analysis plan follows an \textit{intention-to-treat} approach (analysis that includes all randomized participants, regardless of protocol adherence) with \textit{per-protocol} sensitivity analysis, using statistical models appropriate for the hierarchical nature of the data (students nested within groups nested within conditions).

\textbf{Statistical software}:
\begin{itemize}
    \item \textbf{Primary analysis}: R 4.3.0 with lme4, nlme, lavaan packages
    \item \textbf{Power analysis}: G*Power 3.1.9.7
    \item \textbf{Missing data}: Multiple imputation via MICE package
    \item \textbf{Effect sizes}: effsize package for Cohen's $d$ and eta-squared
\end{itemize}

\subsection{Primary analyses}

\textbf{Main statistical model}: Mixed-effects ANOVA for 2×2×2 factorial design:

\begin{equation}
Y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + u_l + \epsilon_{ijkl}
\label{eq:anova-model}
\end{equation}

where:
\begin{itemize}
    \item $Y_{ijkl}$ = outcome for subject $l$ in condition $(i,j,k)$
    \item $\alpha_i$ = main effect of Modality (Pyragogy vs Traditional)
    \item $\beta_j$ = main effect of AI (present vs absent)
    \item $\gamma_k$ = main effect of Duration (8 vs 16 weeks)
    \item $u_l$ = random effect for group
    \item $\epsilon_{ijkl}$ = residual error
\end{itemize}

\textbf{Multiple comparisons correction}: Benjamini-Hochberg procedure for False Discovery Rate control (FDR $< 0{,}05$).

\textbf{Effect size analysis}:
\begin{itemize}
    \item Cohen's $d$ for between-group differences
    \item Partial $\eta^2$ for variance explained by factors
    \item $R^2$ for regression models
\end{itemize}

\subsection{Secondary and exploratory analyses}

\textbf{Moderation Analysis}: Testing interactions between treatment and potential moderators:

\begin{equation}
Y = b_0 + b_1 X + b_2 M + b_3 XM + \text{covariates} + \epsilon
\label{eq:moderation}
\end{equation}

\textbf{Moderators tested}:
\begin{itemize}
    \item Group cognitive diversity (baseline CDI)
    \item Individual differences (Need for Cognition, Growth Mindset)
    \item Baseline collaborative competencies
    \item Instructor characteristics
\end{itemize}

\textbf{Mediation Analysis}: Path analysis using lavaan package to test causal mechanisms:

\begin{align}
M &= a \cdot X + \text{covariates} + \epsilon_1 \label{eq:mediation-a}\\
Y &= c' \cdot X + b \cdot M + \text{covariates} + \epsilon_2 \label{eq:mediation-b}
\end{align}

\textbf{Mediators tested}:
\begin{itemize}
    \item Reciprocity Coefficient (RC)
    \item Average idea quality (EQI)
    \item Group cohesion and psychological safety
    \item Meta-cognitive awareness
\end{itemize}

\textbf{Growth Curve Modeling}: Temporal trajectory analysis using hierarchical linear modeling:

\begin{align}
Y_{ti} &= \pi_{0i} + \pi_{1i} \cdot \text{TIME}_{ti} + \pi_{2i} \cdot \text{TIME}^2_{ti} + \epsilon_{ti} \label{eq:level1}\\
\pi_{0i} &= \beta_{00} + \beta_{01} \cdot \text{TREATMENT}_i + r_{0i} \label{eq:level2-intercept}\\
\pi_{1i} &= \beta_{10} + \beta_{11} \cdot \text{TREATMENT}_i + r_{1i} \label{eq:level2-slope}
\end{align}



\subsection{Missing data and dropout management}

\textbf{Missing Data Pattern Analysis}:
\begin{itemize}
    \item Little's MCAR test to verify completely random missingness
    \item Logistic regression to identify dropout predictors
    \item Pattern-mixture models if missingness is informative
\end{itemize}

\textbf{Multiple Imputation}:
\begin{itemize}
    \item $M = 20$ imputations using mice package
    \item Imputation model includes baseline covariates + treatment assignment
    \item Results pooling using Rubin's rules
\end{itemize}

\textbf{Sensitivity Analysis}:
\begin{itemize}
    \item Complete case analysis
    \item Last-observation-carried-forward
    \item Worst-case scenario imputation
    \item Pattern-mixture models for different missingness assumptions
\end{itemize}

\newpage
\section{Ethical Considerations}
\subsection*{Fundamental Principles:}

The study is designed according to Helsinki Declaration principles and Good Clinical Practice (GCP) guidelines, with particular attention to the vulnerability of university student participants.

\textbf{Autonomy and informed consent}:
\begin{itemize}
    \item \textbf{Two-phase consent process}: General information + specific consent
    \item \textbf{Right of withdrawal}: Ability to withdraw without academic penalization
    \item \textbf{Dynamic consent}: New consent in case of protocol modifications
\end{itemize}

\textbf{Beneficence and non-maleficence}:
\begin{itemize}
    \item \textbf{Risk-benefit assessment}: Minimal risks with potential educational benefits
    \item \textbf{Wellbeing monitoring}: Weekly assessment of stress and anxiety
    \item \textbf{Intervention protocols}: Procedures for managing distress situations
    \item \textbf{Post-study equalization}: Access to most effective treatment for control group
\end{itemize}

\textbf{Justice}:
\begin{itemize}
    \item \textbf{Equitable inclusion}: Balanced representation of gender, ethnicity, socioeconomic status
    \item \textbf{Accessibility}: Accommodations for students with disabilities
    \item \textbf{Benefit distribution}: Results shared with educational community
\end{itemize}

\subsection{Privacy and data protection}

\textbf{Data minimization}: Collection only of data strictly necessary for research objectives.

\textbf{Anonymization and pseudonymization}:
\begin{itemize}
    \item \textbf{Identification codes}: Immediate replacement of identifying data
    \item \textbf{Key coding}: Linking keys stored separately
    \item \textbf{De-identification}: Removal of indirect identifiers in analytical datasets
\end{itemize}

\textbf{Information security}:
\begin{itemize}
    \item \textbf{Encryption}: AES-256 for data at rest and in transit
    \item \textbf{Access control}: Role-based access with multi-factor authentication
    \item \textbf{Audit logs}: Complete tracking of data access
    \item \textbf{Secure backups}: Encrypted copies in geographically separated locations
\end{itemize}

\textbf{Retention and disposal}:
\begin{itemize}
    \item \textbf{Retention period}: 10 years for primary data, 5 for auxiliary data
    \item \textbf{Secure disposal}: Certified procedures for data destruction
    \item \textbf{Archiving policies}: Protocols for responsible long-term archiving
\end{itemize}

\subsection{Institutional approvals}

\textbf{Institutional Review Board (IRB)}:
\begin{itemize}
    \item Preliminary approval obtained from Principal Investigator's IRB
    \item Coordinated review with IRBs of all participating institutions
    \item Annual reporting of adverse events and protocol deviations
\end{itemize}

\textbf{Trial registration}:
\begin{itemize}
    \item Registration on ClinicalTrials.gov before recruitment initiation
    \item Protocol published on open-access repository (OSF)
    \item Adherence to CONSORT guidelines for reporting
\end{itemize}

\newpage
\section{Timeline and Critical Milestones}
\subsection*{General schedule:}

\begin{table}[H]
\centering
\caption{Detailed Timeline of IdeoEvo Project}
\label{tab:project-timeline}
\resizebox{\textwidth}{!}{
\begin{tabular}{p{2.5cm}p{2.5cm}p{8cm}p{2.5cm}}
\toprule
\textbf{Phase} & \textbf{Timeline} & \textbf{Main Activities} & \textbf{Deliverables} \\
\midrule
\textbf{Preparation} & Months 1--3 & 
\begin{itemize}
\item IRB approvals
\item Platform development
\item Facilitator training
\item Pilot testing ($N=24$)
\end{itemize} & Finalized protocol \\
\hline
\textbf{Recruitment} & Months 4--5 & 
\begin{itemize}
\item Recruitment campaigns
\item Screening and baseline assessment
\item Randomization and group formation
\end{itemize} & $N=264$ participants enrolled \\
\hline
\textbf{Intervention 1} & Months 6--7 & 
\begin{itemize}
\item 8-week interventions (4 conditions)
\item Continuous data collection
\item Weekly monitoring
\end{itemize} & Interim analysis \\
\hline
\textbf{Intervention 2} & Months 8--9 & 
\begin{itemize}
\item Additional 8 weeks for 16-week conditions
\item Extended data collection
\item Retention testing
\end{itemize} & Complete dataset \\
\hline
\textbf{Analysis} & Months 10--12 & 
\begin{itemize}
\item Statistical analysis
\item Qualitative coding
\item Results integration
\item Sensitivity analysis
\end{itemize} & Statistical report \\
\hline
\textbf{Dissemination} & Months 13--15 & 
\begin{itemize}
\item Manuscript preparation
\item Conference presentations  
\item Policy recommendations
\item Open data release
\end{itemize} & Submitted publications \\
\bottomrule
\end{tabular}
}
\end{table}
\subsection{Critical milestones}

\textbf{Milestone 1 -- Platform Validation (Month 3):} Completion of pilot test with validation of technological platform and experimental protocols.

\textbf{Success criteria}:
\begin{itemize}
	\item Technical reliability $> 98$\% (uptime, no data loss)
	\item User experience satisfaction $> 4{,}0/5{,}0$
	\item Protocol adherence $> 90$\% in pilot groups
	\item Inter-rater reliability $> 0{,}85$ for qualitative coding
\end{itemize}

\textbf{Milestone 2 -- Recruitment Completion (Month 5):} Achievement of target sample with appropriate diversification.

\textbf{Success criteria}:
\begin{itemize}
	\item $N \geq 264$ participants recruited
	\item Gender balance 45--55\% women
	\item Disciplinary balance 45--55\% Education Sciences students
	\item Dropout rate $\leq 5$\% during baseline assessment
\end{itemize}

\textbf{Milestone 3 -- Data Quality Verification (Month 8):} Interim analysis to verify quality and integrity of collected data.

\textbf{Success criteria}:
\begin{itemize}
	\item Missing data rate $\leq 10$\% for primary outcomes
	\item Protocol adherence $\geq 85$\% in all conditions
	\item No systematic differences in dropout rate between groups
	\item Acceptable reliability for new measures ($\alpha > 0{,}70$)
\end{itemize}

\newpage

\section{Validity Control and Replicability}
\subsection*{Internal validity}

\textbf{Threats to internal validity and countermeasures}:

\textbf{Selection bias}:
\begin{itemize}
	\item \textbf{Threat}: Systematic differences between groups
	\item \textbf{Countermeasure}: Stratified randomization
\end{itemize}

\textbf{Maturation}:
\begin{itemize}
	\item \textbf{Threat}: Natural changes during academic year
	\item \textbf{Countermeasure}: Active control group with same time commitment
\end{itemize}

\textbf{History effects}:
\begin{itemize}
	\item \textbf{Threat}: External events affecting outcomes
	\item \textbf{Countermeasure}: Control for major events, multiple sites
\end{itemize}

\textbf{Contamination}:
\begin{itemize}
	\item \textbf{Threat}: Cross-contamination between experimental conditions
	\item \textbf{Countermeasures}: Cluster randomization, separate facilities, confidentiality agreements
\end{itemize}

\textbf{Researcher effects}:
\begin{itemize}
	\item \textbf{Threat}: Researcher or facilitator bias
	\item \textbf{Countermeasures}: Standardized protocols, multiple facilitators, blinded assessment when possible
\end{itemize}

\subsection{External validity}

\textbf{Sample generalizability}:
\begin{itemize}
	\item \textbf{Target population}: University students in STEM and Education
	\item \textbf{Sampling strategy}: Multi-site recruitment to increase diversity
	\item \textbf{Limitations}: Limited age range, high-performing population
\end{itemize}

\textbf{Setting generalizability}:
\begin{itemize}
	\item \textbf{Ecological validity}: Conducted in genuine educational contexts
	\item \textbf{Multiple contexts}: Different universities, class formats, disciplines
	\item \textbf{Limitations}: Controlled duration, artificial problem scenarios
\end{itemize}

\textbf{Treatment generalizability}:
\begin{itemize}
	\item \textbf{Implementation fidelity}: Standardized training, protocol adherence monitoring
	\item \textbf{Adaptation allowances}: Guidelines for contextual modifications
	\item \textbf{Documentation}: Complete protocol documentation for replication
\end{itemize}

\subsection{Replicability protocols}

\textbf{Open Science Practices}:
\begin{itemize}
	\item \textbf{Pre-registration}: Complete protocol on OSF before data collection
	\item \textbf{Open materials}: All instruments, training materials, platform code
	\item \textbf{Open data}: De-identified dataset with detailed codebook
	\item \textbf{Open analyses}: Complete R scripts for all analyses
\end{itemize}

\textbf{Replication Package}:
\begin{itemize}
	\item \textbf{Complete protocol}: Step-by-step implementation guide
	\item \textbf{Training materials}: Facilitator certification program
	\item \textbf{Technology package}: Open-source platform with installation guide
	\item \textbf{Assessment tools}: Validated instruments with scoring rubrics
\end{itemize}

\section{Feasibility Analysis and Risk Management}
\subsection*{Feasibility assessment:}

\textbf{Technical feasibility}:
\begin{itemize}
	\item \textbf{Platform development:} In progress, with six months of development already carried out.
	\item \textbf{AI integration}: Partnership with tech companies for computational resources
	\item \textbf{Data infrastructure}: Scalable cloud-based architecture.
\end{itemize}

\textbf{Operational feasibility}:
\begin{itemize}
	\item \textbf{Recruitment capacity}: Access to $>5,000$ students across 10 universities, ensuring geographic and cultural diversity.
	\item \textbf{Spaces and facilities}: Dedicated research laboratories with recording capabilities.
	\item \textbf{Personnel}: Team of 10 researchers, 12 trained facilitators.
\end{itemize}

\textbf{Economic feasibility}:
\begin{itemize}
	\item \textbf{Total budget}: €450,000 over 15 months.
	\item \textbf{Secured funding}: €350,000 from research grants.
	\item \textbf{Cost per participant}: €1,400 (comparable with similar studies).
\end{itemize}

\subsection{Risk assessment and mitigation}

\textbf{High-risk factors}:

\textbf{Risk 1 -- Low recruitment rate}
\begin{itemize}
	\item \textbf{Probability}: Medium (30\%).
	\item \textbf{Impact}: High (underpowered study).
	\item \textbf{Mitigation}: Early recruitment campaigns, increased incentives, timeline extension.
\end{itemize}

\textbf{Risk 2 -- High dropout rate}
\begin{itemize}
	\item \textbf{Probability}: Medium (25\%).
	\item \textbf{Impact}: Medium (reduced power, bias).
	\item \textbf{Mitigation}: Enhanced engagement strategies, flexible scheduling, retention bonuses.
\end{itemize}

\textbf{Risk 3 -- Technical failures}
\begin{itemize}
	\item \textbf{Probability}: Low (15\%).
	\item \textbf{Impact}: High (data loss, protocol deviation).
	\item \textbf{Mitigation}: Redundant systems, real-time backups, rapid response team.
\end{itemize}

\textbf{Medium-risk factors}:

\textbf{Risk 4 -- Implementation fidelity problems}
\begin{itemize}
	\item \textbf{Probability}: Medium (35\%).
	\item \textbf{Impact}: Medium (reduced internal validity).
	\item \textbf{Mitigation}: Extensive training, monitoring protocols, rapid feedback.
\end{itemize}

\textbf{Risk 5 -- Institutional resistance}
\begin{itemize}
	\item \textbf{Probability}: Low (20\%).
	\item \textbf{Impact}: Medium (access restrictions).
	\item \textbf{Mitigation}: Early stakeholder engagement, clear benefit communication.
\end{itemize}

\textbf{Contingency plans}:
\begin{itemize}
	\item \textbf{Sample size adjustment}: Power calculations for different $N$ scenarios.
	\item \textbf{Protocol modifications}: Pre-approved variations for different contexts.
	\item \textbf{Timeline flexibility}: 3-month buffer for critical milestones.
	\item \textbf{Alternative analyses}: Bayesian approaches if frequentist underpowered.
\end{itemize}

\section{Expected Impact and Dissemination}
\subsection*{Expected scientific contributions}

\textbf{Theoretical contributions}:
\begin{itemize}
	\item First rigorous empirical validation of educational framework based on evolutionary principles.
	\item Evidence for effectiveness of ``idea-centered'' vs. ``person-centered'' competition.
	\item Formalization of cognitive reciprocity mechanisms.
	\item Integration of procedural AI in collaborative learning.
\end{itemize}

\textbf{Methodological contributions}:
\begin{itemize}
	\item New assessment tools for collaborative intelligence of automated EQI calculation.
	\item Mixed-methods framework for evaluating complex educational interventions.
	\item Open-source platform for replication and scale-up.
\end{itemize}

\textbf{Practical contributions}:
\begin{itemize}
	\item Evidence-based alternative to competitive educational models.
	\item Scalable framework for educational institutions.
	\item Policy recommendations for educational reform.
	\item Teacher training curricula for 21st-century skills.
\end{itemize}

\subsection{Dissemination strategy}

\textbf{Academic dissemination}:
\begin{itemize}
	\item \textbf{High-impact journals}: Educational Researcher, Learning and Instruction, Computers \& Education.
	\item \textbf{Conferences}: AERA, ICLS, Learning Sciences, AIED.
	\item \textbf{Special issues}: Editorship for special issues on educational innovation.
\end{itemize}

\textbf{Professional dissemination}:
\begin{itemize}
	\item \textbf{Practitioner publications}: Educational Leadership, Phi Delta Kappan.
	\item \textbf{Professional conferences}: ASCD, ISTE, regional educational conferences.
	\item \textbf{Workshops}: Practical sessions for educators and administrators.
\end{itemize}

\textbf{Policy dissemination}:
\begin{itemize}
	\item \textbf{Policy briefs}: Concise summaries for decision-makers.
	\item \textbf{Government presentations}: Ministry of Education briefings.
	\item \textbf{Think tank collaborations}: Educational policy institutes.
\end{itemize}

\textbf{Public dissemination}:
\begin{itemize}
	\item \textbf{Media engagement}: Science journalism, educational media.
	\item \textbf{Social media}: Twitter threads, LinkedIn articles, YouTube videos.
	\item \textbf{Popular publications}: Articles in education magazines.
\end{itemize}

\newpage

\section{Summary and Significance of the Study}

The IdeoEvo Project represents the first systematic attempt at empirical validation of the pyragogic framework under rigorous experimental conditions. The 2×2×2 factorial design with $N=264$ participants provides sufficient power to detect theoretically meaningful and practically relevant effect sizes.

The integration of quantitative and qualitative methods, standardized and innovative instruments, and multiple analytical perspectives ensures a comprehensive evaluation of model effectiveness. Open science and replicability protocols facilitate independent validation and extension of the study across different contexts.

The expected results have the potential to transform theoretical understanding of collaborative learning and provide empirical evidence for reforming obsolete educational practices. The project positions itself as a critical bridge between innovative theory and practical implementation, contributing both to the science of education and to concrete improvement of educational outcomes for future generations.

In the next chapter we will explore the broader implications of these expected results, discussing how empirical validation of Pyragogy could catalyze systemic transformations in contemporary educational paradigms.
gms.